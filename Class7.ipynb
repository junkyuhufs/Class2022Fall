{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0Q28nplBD8H7nRhk7e/ew",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/junkyuhufs/Class2022Fall/blob/main/Class7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Natural Language Processing (NLP)\n",
        "##Text Processing\n",
        "\n",
        "by virtue of Dr. Hosung Nam"
      ],
      "metadata": {
        "id": "DSpZNqeZg6oW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tokenization"
      ],
      "metadata": {
        "id": "fhGzdX6PhFg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "MLBijg9gg5x4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aCLOGP6SgMSu"
      },
      "outputs": [],
      "source": [
        "# copy a file from github\n",
        "import os\n",
        "url = \"https://raw.githubusercontent.com/junkyuhufs/Class2022Fall/main/crime_punishment.txt\"\n",
        "os.system(\"curl \" + url + \" > crime_punishment.txt\")\n",
        "\n",
        "# copy a file from github\n",
        "import os\n",
        "url = \"https://raw.githubusercontent.com/hsnam95/class2022Spring/main/crime_punishment.txt\"\n",
        "os.system(\"curl \" + url + \" > crime_punishment.txt\")\n",
        "\n",
        "# read a text file in the server\n",
        "file = open(\"crime_punishment.txt\")\n",
        "text = file.read().replace(\"\\n\", \" \")\n",
        "file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternative (직접 붙이기)"
      ],
      "metadata": {
        "id": "bSfS7b0xhxx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# or copy/pase text here\n",
        "text = 'Here’s to the crazy ones, the misfits, the rebels, the troublemakers, the round pegs in the square holes. \\\n",
        "The ones who see things differently — they’re not fond of rules. \\\n",
        "You can quote them, disagree with them, glorify or vilify them, \\\n",
        "but the only thing you can’t do is ignore them because they change things. \\\n",
        "They push the human race forward, and while some may see them as the crazy ones, we see genius, \\\n",
        "because the ones who are crazy enough to think that they can change the world, are the ones who do.'"
      ],
      "metadata": {
        "id": "EKFWSLaVh3Pd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# write out a text file\n",
        "file = open(\"tmp.txt\", \"w\")\n",
        "file.write(text)\n",
        "file.close()"
      ],
      "metadata": {
        "id": "kM7s4QG_h-7t"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text.split()"
      ],
      "metadata": {
        "id": "uvfrsPVniH6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(text.split())"
      ],
      "metadata": {
        "id": "OroSzOggiPA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "words = word_tokenize(text)"
      ],
      "metadata": {
        "id": "u4kbGcdCiRKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "retokenize = RegexpTokenizer(\"[\\w]+\")\n",
        "words = retokenize.tokenize(text)"
      ],
      "metadata": {
        "id": "0Xghdzd2iWxe"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Normalization\n",
        "##Stemming 어간 추출 대충의 패턴 규칙으로 어미를 잘라내는 것 (사전에 없는 어간 나올 수 있음)\n",
        "\n",
        "##Lemmatization 표제어(기본 사전형) 추출."
      ],
      "metadata": {
        "id": "zNYkM9_Nijrb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "[stemmer.stem(w) for w in words]"
      ],
      "metadata": {
        "id": "Mmz_HmtoinlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import LancasterStemmer\n",
        "stemmer = LancasterStemmer()\n",
        "[stemmer.stem(w) for w in words]"
      ],
      "metadata": {
        "id": "IO3LYXiEiteP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Stopword"
      ],
      "metadata": {
        "id": "oh7QVujIjoHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords  \n",
        "nltk.download('stopwords')\n",
        "print(words)\n",
        "words = [w for w in words if not w in stopwords.words('english')]\n",
        "print(words)"
      ],
      "metadata": {
        "id": "_E099hHvjqII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Collocation, Concordance"
      ],
      "metadata": {
        "id": "rbrlvMvmjwxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('gutenberg')\n",
        "text = nltk.corpus.gutenberg.raw('austen-emma.txt')\n",
        "words = retokenize.tokenize(text)"
      ],
      "metadata": {
        "id": "0ypb8fXsjyCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.Text(words).collocations()  # default: (num=20, window_size=2)"
      ],
      "metadata": {
        "id": "CjLqFQ6Mj1YJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.Text(words).concordance('Emma', 79, 10)"
      ],
      "metadata": {
        "id": "uvCyUYI2j9Fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.Text(words).dispersion_plot([\"Emma\", \"Knightley\", \"Frank\", \"Jane\", \"Harriet\", \"Robert\"])"
      ],
      "metadata": {
        "id": "og7UCpsdkD0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distributional similarity: \n",
        "# find other words which appear in the same contexts as the specified word; \n",
        "# list most similar words first.\n",
        "nltk.Text(words).similar(\"Emma\")"
      ],
      "metadata": {
        "id": "6PYq78sTkJea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find contexts where the specified words appear; list most frequent common contexts first.\n",
        "nltk.Text(words).common_contexts([\"Emma\", \"she\"])"
      ],
      "metadata": {
        "id": "51Qkvu4IkPFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Frequency distribution, Frequency plot"
      ],
      "metadata": {
        "id": "jkjbVWVgkT_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fd = nltk.FreqDist(words).most_common(20)\n",
        "fd"
      ],
      "metadata": {
        "id": "mEs7z3nzkVka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.Text(words).plot(20)"
      ],
      "metadata": {
        "id": "cxsXvjvDkZrK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}